{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring Diagnosis for New Subjects\n",
    "\n",
    "This notebook demonstrates how to use a **trained sLDA model** to infer:\n",
    "1. **Diagnosis probabilities** for new subjects\n",
    "2. **Topic mixtures** (co-pathology patterns)\n",
    "3. **Comparison** to training subjects\n",
    "\n",
    "## Workflow\n",
    "\n",
    "```\n",
    "Trained Model (β, η) + New Subject (X_new)\n",
    "           ↓\n",
    "    Infer θ_new (topic mixture)\n",
    "           ↓\n",
    "    Compute P(DX | θ_new)\n",
    "           ↓\n",
    "    Diagnosis Probabilities\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model\n",
    "\n",
    "First, we need a trained model. If you haven't trained one yet, run `slda_copathology_example.ipynb` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_wsev_data, prepare_slda_inputs, train_test_split_stratified\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mslda_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoPathologySLDA\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from preprocessing import load_wsev_data, prepare_slda_inputs, train_test_split_stratified\n",
    "from slda_model import CoPathologySLDA\n",
    "from inference_new_subjects import (\n",
    "    infer_new_subject,\n",
    "    print_inference_results,\n",
    "    infer_batch_subjects,\n",
    "    compare_subject_to_training\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Train a new model (or load existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = '/home/coder/data/updated_WSEV/260108_wsev_final_df.csv'\n",
    "df = load_wsev_data(data_path)\n",
    "X, y, feature_names, dx_labels = prepare_slda_inputs(df)\n",
    "\n",
    "print(f\"Loaded {len(X)} subjects\")\n",
    "print(f\"Features: {len(feature_names)}\")\n",
    "print(f\"Diagnoses: {dx_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test to simulate new subjects\n",
    "X_train, X_test, y_train, y_test = train_test_split_stratified(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} subjects\")\n",
    "print(f\"Test set (simulating new subjects): {len(X_test)} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model (or load if already trained)\n",
    "# For faster testing, use fewer samples\n",
    "\n",
    "model = CoPathologySLDA(n_topics=4, alpha_prior=1.0, random_state=42)\n",
    "\n",
    "print(\"Training model on training set...\")\n",
    "print(\"Note: This may take 5-15 minutes. Reduce n_samples for faster testing.\\n\")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_samples=1000,  # Increase to 2000 for final analysis\n",
    "    tune=500,        # Increase to 1000 for final analysis\n",
    "    chains=2,        # Increase to 4 for final analysis\n",
    "    target_accept=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Load a previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to load a saved model\n",
    "# import pickle\n",
    "# with open('trained_slda_model.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Infer Single New Subject\n",
    "\n",
    "Let's take a subject from the test set and infer their diagnosis and topic mixture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a new subject from test set\n",
    "subject_idx = 0\n",
    "X_new_subject = X_test[subject_idx]\n",
    "true_diagnosis = dx_labels[y_test[subject_idx]]\n",
    "\n",
    "print(f\"Analyzing new subject (index {subject_idx})\")\n",
    "print(f\"True diagnosis: {true_diagnosis}\")\n",
    "print(f\"Features shape: {X_new_subject.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer diagnosis and topic mixture\n",
    "results = infer_new_subject(\n",
    "    model,\n",
    "    X_new_subject,\n",
    "    feature_names,\n",
    "    dx_labels,\n",
    "    subject_id=f\"Test_Subject_{subject_idx}\"\n",
    ")\n",
    "\n",
    "# Print detailed results\n",
    "print_inference_results(results, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topic mixture\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Topic mixture\n",
    "topics = [f'Topic {i}' for i in range(len(results['topic_mixture']))]\n",
    "ax1.bar(topics, results['topic_mixture'], color='steelblue', alpha=0.7)\n",
    "ax1.set_ylabel('Proportion', fontsize=12)\n",
    "ax1.set_title(f\"Topic Mixture for {results['subject_id']}\", fontsize=13, fontweight='bold')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Diagnosis probabilities\n",
    "dx_names = list(results['diagnosis_breakdown'].keys())\n",
    "dx_probs = list(results['diagnosis_breakdown'].values())\n",
    "colors = ['green' if dx == results['predicted_diagnosis'] else 'gray' for dx in dx_names]\n",
    "\n",
    "ax2.bar(dx_names, dx_probs, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Probability', fontsize=12)\n",
    "ax2.set_title('Diagnosis Probabilities', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axhline(0.5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='50% threshold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrue diagnosis: {true_diagnosis}\")\n",
    "print(f\"Predicted diagnosis: {results['predicted_diagnosis']}\")\n",
    "print(f\"Correct: {'✓' if true_diagnosis == results['predicted_diagnosis'] else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interpret Co-Pathology\n",
    "\n",
    "The topic mixture tells us about co-pathology patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic patterns from model\n",
    "topic_patterns = model.get_topic_patterns()\n",
    "\n",
    "print(\"\\nTopic Interpretation for this Subject:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for topic_id, proportion in results['top_topics']:\n",
    "    if proportion < 0.05:  # Skip negligible topics\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nTopic {topic_id} ({proportion:.1%} of pathology):\")\n",
    "\n",
    "    # Get top regions for this topic\n",
    "    top_regions = model.get_topic_top_regions(\n",
    "        topic_id,\n",
    "        feature_names,\n",
    "        n_regions=5,\n",
    "        absolute=True\n",
    "    )\n",
    "\n",
    "    print(\"  Top affected regions:\")\n",
    "    for region, weight in top_regions:\n",
    "        region_clean = region.replace('ctx_lh_', 'L_').replace('ctx_rh_', 'R_')\n",
    "        print(f\"    - {region_clean}: {weight:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare to Training Subjects\n",
    "\n",
    "Compare the new subject's topic mixture to typical patterns in each diagnosis group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to training subjects\n",
    "comparison = compare_subject_to_training(\n",
    "    model,\n",
    "    X_new_subject,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    dx_labels,\n",
    "    subject_id=f\"Test_Subject_{subject_idx}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nSimilarity to Training Diagnosis Groups:\")\n",
    "print(\"=\"*50)\n",
    "for dx, similarity in sorted(comparison['similarities'].items(),\n",
    "                             key=lambda x: x[1], reverse=True):\n",
    "    bar = \"█\" * int(similarity * 40)\n",
    "    print(f\"{dx:<10} {similarity:.3f}  {bar}\")\n",
    "\n",
    "print(f\"\\nMost similar to: {comparison['most_similar_dx']}\")\n",
    "print(f\"True diagnosis: {true_diagnosis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Inference for Multiple New Subjects\n",
    "\n",
    "Infer diagnoses for all test subjects at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer for all test subjects\n",
    "test_subject_ids = [f\"Test_Subject_{i}\" for i in range(len(X_test))]\n",
    "\n",
    "results_df = infer_batch_subjects(\n",
    "    model,\n",
    "    X_test,\n",
    "    feature_names,\n",
    "    dx_labels,\n",
    "    subject_ids=test_subject_ids\n",
    ")\n",
    "\n",
    "# Add true diagnoses for comparison\n",
    "results_df['True_DX'] = [dx_labels[y] for y in y_test]\n",
    "results_df['Correct'] = results_df['Predicted_DX'] == results_df['True_DX']\n",
    "\n",
    "print(f\"\\nBatch Inference Results for {len(results_df)} test subjects:\")\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "accuracy = results_df['Correct'].mean()\n",
    "print(f\"\\nOverall Accuracy on Test Set: {accuracy:.1%}\")\n",
    "\n",
    "# Per-diagnosis accuracy\n",
    "print(\"\\nPer-Diagnosis Accuracy:\")\n",
    "for dx in dx_labels:\n",
    "    dx_mask = results_df['True_DX'] == dx\n",
    "    if dx_mask.sum() > 0:\n",
    "        dx_accuracy = results_df[dx_mask]['Correct'].mean()\n",
    "        print(f\"  {dx}: {dx_accuracy:.1%} ({dx_mask.sum()} subjects)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('test_subjects_inference_results.csv', index=False)\n",
    "print(\"\\nResults saved to: test_subjects_inference_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify Uncertain Cases\n",
    "\n",
    "Find subjects with low confidence or mixed pathology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find low confidence predictions\n",
    "low_confidence_threshold = 0.5\n",
    "uncertain_subjects = results_df[results_df['DX_Confidence'] < low_confidence_threshold]\n",
    "\n",
    "print(f\"\\nSubjects with low confidence (< {low_confidence_threshold:.0%}):\")\n",
    "print(f\"Found {len(uncertain_subjects)} uncertain cases\\n\")\n",
    "\n",
    "if len(uncertain_subjects) > 0:\n",
    "    display_cols = ['Subject_ID', 'True_DX', 'Predicted_DX', 'DX_Confidence', 'Correct']\n",
    "    print(uncertain_subjects[display_cols])\n",
    "else:\n",
    "    print(\"No uncertain cases found - all predictions are confident!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find subjects with mixed topic membership (co-pathology)\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Compute entropy for each subject's topic mixture\n",
    "topic_cols = [col for col in results_df.columns if col.startswith('Topic_')]\n",
    "topic_mixtures = results_df[topic_cols].values\n",
    "\n",
    "results_df['Topic_Entropy'] = [entropy(mix) for mix in topic_mixtures]\n",
    "\n",
    "# High entropy = mixed topics = co-pathology\n",
    "high_entropy_subjects = results_df.nlargest(10, 'Topic_Entropy')\n",
    "\n",
    "print(\"\\nTop 10 Subjects with Co-Pathology (High Topic Entropy):\\n\")\n",
    "display_cols = ['Subject_ID', 'True_DX', 'Predicted_DX', 'Topic_Entropy'] + topic_cols\n",
    "print(high_entropy_subjects[display_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Example: Real-World New Subject\n",
    "\n",
    "If you have a completely new subject's data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Manual input for a new subject\n",
    "# Replace with actual atrophy values from your subject\n",
    "\n",
    "# Load new subject from CSV (example)\n",
    "# new_subject_df = pd.read_csv('/path/to/new_subject_data.csv')\n",
    "# X_new = new_subject_df[feature_names].values[0]\n",
    "\n",
    "# Or create manually (must have 62 cortical features)\n",
    "# X_new = np.array([0.5, 0.3, ..., 0.8])  # 62 values\n",
    "\n",
    "# Then infer:\n",
    "# results = infer_new_subject(\n",
    "#     model,\n",
    "#     X_new,\n",
    "#     feature_names,\n",
    "#     dx_labels,\n",
    "#     subject_id=\"PATIENT_NEW_001\"\n",
    "# )\n",
    "# print_inference_results(results)\n",
    "\n",
    "print(\"\\nTo use with your own new subject:\")\n",
    "print(\"1. Extract 62 cortical features (ctx_lh_* and ctx_rh_*)\")\n",
    "print(\"2. Ensure features are in the same order as training data\")\n",
    "print(\"3. Use infer_new_subject() as shown above\")\n",
    "print(\"4. Interpret topic mixture for co-pathology patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Can Infer for New Subjects:\n",
    "\n",
    "1. **Diagnosis Probabilities**: P(AD), P(PD), P(DLB), P(SVAD), P(HC)\n",
    "2. **Topic Mixture**: Proportion of each pathology pattern (θ)\n",
    "3. **Co-Pathology**: Mixed topic membership indicates overlapping pathologies\n",
    "4. **Similarity**: How similar to typical patterns in each diagnosis group\n",
    "\n",
    "### Key Functions:\n",
    "\n",
    "- `infer_new_subject()`: Single subject inference with detailed results\n",
    "- `infer_batch_subjects()`: Batch inference returning DataFrame\n",
    "- `compare_subject_to_training()`: Compare to training diagnosis groups\n",
    "- `print_inference_results()`: Pretty print results\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **High confidence + single dominant topic**: Clear single pathology\n",
    "- **High confidence + mixed topics**: Clear co-pathology pattern\n",
    "- **Low confidence**: Uncertain or atypical presentation\n",
    "- **High entropy**: Multiple co-occurring pathology patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slda_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
